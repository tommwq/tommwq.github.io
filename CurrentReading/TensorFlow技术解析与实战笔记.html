<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-09-23 周一 18:44 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>TensorFlow技术解析与实战笔记</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">TensorFlow技术解析与实战笔记</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org64f1595">人工神经网络</a></li>
<li><a href="#org96259af">人工神经网络的训练</a></li>
<li><a href="#org254564a">TensorFlow系统架构</a></li>
<li><a href="#org43daaf9">TensorFlow编程模型</a></li>
</ul>
</div>
</div>

<div id="outline-container-org64f1595" class="outline-2">
<h2 id="org64f1595">人工神经网络</h2>
<div class="outline-text-2" id="text-org64f1595">
<p>
人工神经网络是一种机器学习算法。它是受到人类大脑的神经结构的启发而建立的。人工神经网络由一组节点（叫做神经元）组成。一个神经元从其他的一些神经元得到输出，计算出一个值，传递给另外一些神经元。从逻辑上看，神经元就是 \(R^n \rightarrow R\) 函数。
</p>

<p>
如果神经元a接收神经元b产生的值，我们就称它们之间存在连接。根据神经元之间连接结构的不同，人工神经网络可以分为前向传播网络、循环神经网络等。前向传播网络的结构比较简单，它可以分为若干个层。第k层中的神经元，从k-1层神经元得到输入数据，并将值输出给k+1层的神经元。第1层也叫做输入层，最后一层叫做输出层，其余的叫做隐藏层。每一层的神经元数不需要相等。假设一个前向神经网络有k层，每层的神经元数是 \(n_k\) ，那么第i层就是一个 \(R^{n_{i-1}} \rightarrow R^{n_{i+1}}\) 映射。如果把这个映射记为 \(f_i\) ，前向神经网络就是k个映射的合成：\(f_1 \circ f_2 \circ \cdots \circ f_k\) 。
</p>

<p>
现在回过头来看神经元。我们已经知道，神经元是 \(R^n \rightarrow R\) 函数。要如何设计神经元呢？最早的做法是选择一个线性函数 \(x \rightarrow w^Tx+b\) 。w叫做权重向量，b叫做偏置。线性函数具有实现简单，计算量小的优点。但是线性神经元无法学习非线性函数，而现实中的问题大多数都是非线性的。为了解决这个问题，同事又尽可能保留线性神经元的优点，可以在线性函数的基础上，增加一个简单非线性函数，即 \(x \rightarrow f(w^Tx+b)\) 。目前大部分神经元都采用这种方式设计。这里的函数 \(f(x)\) 叫做激活函数。常用的激活函数有ReLU、Sigmoid、tanh等。
</p>
</div>
</div>

<div id="outline-container-org96259af" class="outline-2">
<h2 id="org96259af">人工神经网络的训练</h2>
<div class="outline-text-2" id="text-org96259af">
<p>
从前面的公式可以看到，一个神经元由三个要素决定：激活函数、权重向量和偏置。激活函数在设计神经网络架构的时候已经确定，权重向量和偏置是可以动态调整的。通过调整它们来提升神经网络表现的过程叫做训练或学习。
</p>


<p>
假设对于输入 \(x\) ，如何神经网络的输出 \(y = f(x)\)  呢？一种方法是我们设定一个期望的结果 \(y'\) ，将其与实际结果 \(y\) 进行比较。这种方法是
</p>

<p>
p21
</p>
</div>
</div>


<div id="outline-container-org254564a" class="outline-2">
<h2 id="org254564a">TensorFlow系统架构</h2>
<div class="outline-text-2" id="text-org254564a">
<p>
TensorFlow分为应用层、编程接口层、图计算层、数据操作层、网络层和设备层。
应用层包括训练和预测相关的类库，包括最常用的类和函数。
编程接口层包括Python、C++、Java等语言的基础编程接口。
图计算层包括分布式计算图和本地计算图。
数据操作层包括Const、Var、Matmul、Conv2D、ReLU等函数。
网络层包括gRPC、RDMA。
设备层包括CPU、GPU等。
</p>
</div>
</div>


<div id="outline-container-org43daaf9" class="outline-2">
<h2 id="org43daaf9">TensorFlow编程模型</h2>
<div class="outline-text-2" id="text-org43daaf9">
<p>
一个神经网络可以用一个图来描述。图中的节点是神经网络中的一层。图中的边表示节点的连接关系。连接关系有两种：
数据依赖和控制依赖。数据依赖表示有数据流通，控制依赖表示并发控制。节点表示一个操作，通常是神经网络中的一层。
从逻辑上看，节点是一个函数（算子）。建立一个图之后，可以运行图。图的运行环境叫做会话（session）。会话将图中的节点分配到设备（device）上执行。
设备是运算硬件（如CPU、GPU）的抽象。
</p>



<p>
下面是一个学习xor函数的例子：
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #b22222;"># </span><span style="color: #b22222;">&#23398;&#20064;xor&#20989;&#25968;</span>
<span style="color: #b22222;"># </span><span style="color: #b22222;">TODO &#25913;&#20026;Graph/Session&#25509;&#21475;&#12290;</span>
<span style="color: #a020f0;">import</span> numpy <span style="color: #a020f0;">as</span> np
<span style="color: #a020f0;">import</span> tensorflow <span style="color: #a020f0;">as</span> tf
<span style="color: #a020f0;">from</span> tensorflow.layers <span style="color: #a020f0;">import</span> Dense
<span style="color: #a020f0;">from</span> tensorflow.keras.models <span style="color: #a020f0;">import</span> Sequential
<span style="color: #a020f0;">from</span> tensorflow.nn <span style="color: #a020f0;">import</span> relu, sigmoid

<span style="color: #b22222;"># </span><span style="color: #b22222;">&#24314;&#31435;&#22270;</span>
<span style="color: #a0522d;">model</span> = Sequential()
<span style="color: #b22222;"># </span><span style="color: #b22222;">&#21521;&#22270;&#20013;&#28155;&#21152;&#33410;&#28857;</span>
model.add(Dense(16, input_shape=(2,), activation=tf.nn.relu))
model.add(Dense(1, activation=tf.nn.sigmoid))

<span style="color: #b22222;"># </span><span style="color: #b22222;">&#32534;&#35793;&#22270;</span>
model.<span style="color: #483d8b;">compile</span>(
    optimizer=<span style="color: #8b2252;">"adam"</span>,
    loss=<span style="color: #8b2252;">"MSE"</span>,
    metrics=[<span style="color: #8b2252;">"binary_accuracy"</span>]
)

<span style="color: #b22222;"># </span><span style="color: #b22222;">&#20351;&#29992;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;</span>
<span style="color: #a0522d;">samples</span> = np.array([0, 0, 0, 1, 1, 0, 1, 1]).reshape(4, 2)
<span style="color: #a0522d;">labels</span> = np.array([0, 1, 1, 0]).reshape(4, 1)
model.fit(samples, labels, epochs=500)

<span style="color: #b22222;"># </span><span style="color: #b22222;">&#20351;&#29992;&#27169;&#22411;&#39044;&#27979;</span>
<span style="color: #a0522d;">results</span> = model.predict(samples)

<span style="color: #b22222;"># </span><span style="color: #b22222;">&#36755;&#20986;&#32467;&#26524;</span>
<span style="color: #a020f0;">print</span>(<span style="color: #8b2252;">"predict:"</span>)
<span style="color: #a020f0;">print</span>(results.<span style="color: #483d8b;">round</span>().reshape(4).astype(<span style="color: #483d8b;">int</span>))

<span style="color: #a020f0;">print</span>(<span style="color: #8b2252;">"expected:"</span>)
<span style="color: #a020f0;">print</span>(labels.<span style="color: #483d8b;">round</span>().reshape(4))
</pre>
</div>

<p>
Graph是一组tf.Operation和tf.Tensor。tf.Operation是操作，Tensor是数据。
tf.Dense = activation(input * kernel + bias)
</p>


<p>
图中的节点也叫做算子或操作（operation，op）。下面是tf预定义的算子：
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">数学运算</td>
<td class="org-left">add</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">subtract</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">multiply</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">div</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">exp</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">log</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">greater</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">less</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">equal</td>
</tr>

<tr>
<td class="org-left">数组运算</td>
<td class="org-left">concat</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">slice</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">split</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">constant</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">rank</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">shape</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">shuffle</td>
</tr>

<tr>
<td class="org-left">矩阵</td>
<td class="org-left">matmul</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">matrixinverse</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">matrixdeterminant</td>
</tr>

<tr>
<td class="org-left">状态</td>
<td class="org-left">variable</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">assign</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">assignadd</td>
</tr>

<tr>
<td class="org-left">激活函数</td>
<td class="org-left">softmax</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">sigmoid</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">relu</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">convolution2d</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">maxpool</td>
</tr>

<tr>
<td class="org-left">检查点</td>
<td class="org-left">save</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">restore</td>
</tr>

<tr>
<td class="org-left">队列</td>
<td class="org-left">enqueue</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">dequeue</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">mutexacquire</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">mutexrelease</td>
</tr>

<tr>
<td class="org-left">流动控制</td>
<td class="org-left">merge</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">switch</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">enter</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">leave</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">nextiterator</td>
</tr>
</tbody>
</table>


<p>
创建变量：
</p>
<div class="org-src-container">
<pre class="src src-python">tf.Variable(0, name=<span style="color: #8b2252;">"counter"</span>)
</pre>
</div>

<p>
常量：
</p>
<div class="org-src-container">
<pre class="src src-python">tf.constant(3.0)
</pre>
</div>

<p>
数据填充
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #a0522d;">input1</span> = tf.placeholder(tf.float32)
<span style="color: #a0522d;">input2</span> = tf.placeholder(tf.float32)
<span style="color: #a0522d;">output</span> = tf.multiply(input1, input2)
<span style="color: #a020f0;">with</span> tf.Session() <span style="color: #a020f0;">as</span> session:
    <span style="color: #a020f0;">print</span>(session.run([output], feed_dict={input1: [7.], input2: [2.]})
</pre>
</div>

<p>
内核（kernel）是在特定设备上对某个操作的实现。
</p>


<p>
图操作
</p>
<div class="org-src-container">
<pre class="src src-python">tf.Graph
tf.Graph.as_default()
tf.Graph.device(device_name_or_function)
tf.Graph.name_scope(name)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python">tf.Operation
.name
.<span style="color: #483d8b;">type</span>
.inputs
.outpus
.control_inputs
.run(feed_dict=<span style="color: #008b8b;">None</span>, session=<span style="color: #008b8b;">None</span>)
.get_attr(name)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python">tf.Tensor
.dtype
.name
.value_index
.graph
.op
.consumers()
.<span style="color: #483d8b;">eval</span>(feed_dict=<span style="color: #008b8b;">None</span>, session=<span style="color: #008b8b;">None</span>)
.get_shape()
.set_shape(shape)
.device
</pre>
</div>



<p>
读论文
《Mastering the game of Go with deep neural networks and tree search》
</p>

<p>
学习几个网络
LeNet
GoogleNet
AlexNet
LSTM
GAN
</p>


<p>
学习Python库numpy、matplotlib。
scikit-image图像预处理
librosa音频处理
nltk语料库
tensorboard
</p>

<p>
分类（classification）算法的目标是建立特征（feature）到标记（label）的映射关系。
分类通常使用监督学习来完成。聚类（clustering）尝试将一组具有标记的对象划分为若干个组，
每个组内的对象具有一定的相似性。
</p>

<p>
激活函数
sigmoid
S(x) = 1/(1+exp(-x))
sigmoid的值域是(0,1)，单调连续。sigmoid具有软饱和性（lim h'(x) = 0。硬饱和性 存在c，当x&gt;c时，h'(x)=0）
，当x落入饱和区，会产生梯度消失。
</p>


<p>
tanh
tanh(x) = (1 - exp(-2x)) / (1 + exp(-2x))
收敛速度比sigmoid块，仍然有软饱和性。
</p>

<p>
relu
f(x) = max(x, 0)
当x&lt;0时，relu硬饱和，此时权重无法再更新，叫做神经元死亡。当x&gt;0时，f'(x)是1，因此收敛速度较快。
</p>

<p>
softplu是relu的平滑版本
f(x) = log(1 + exp(x))
</p>


<p>
dropout
以1/keep_prob的概率被抑制。抑制时神经元输出0。
</p>

<p>
tanh适用于数据特征差异明显，需要规范化。sigmoid适用于特征不明显，也需要规范化。relu不需要规范化。
</p>


<p>
分类函数
sigmoid_cross_entropy_with_logits
softmax
log_softmax
softmax_cross_entropy_with_logits
</p>

<p>
优化器
GradientDescent 梯度下降
Adadelta 
Adagrad
AdagradDAO
Momentum
Adam
Ftrl
RMSProp
</p>

<p>
保存图：
tf.train.Saver.save() 生成.ckpt检查点文件
Saver.restore()
tf.train.write_graph()
tf.train.import_graph_def()
</p>

<p>
论文：
An overview of gradient descent optimization algorithms
</p>

<p>
假设f和g是 \(R^1\) 上的两个可积函数，函数
\[
\int_{-\inf}^{+\inf}f(\tau)g(x-E)d\tau
\]
是f和g的卷积（convolution）。
</p>

<p>
卷积神经网络通过卷积核（conventional kernel）来进行特征提取，这个操作叫做padding。
</p>

<p>
LeCun
LeNet <a href="http://vision.standford.edu/cs598_spring07/papers/Lecun98.pdf">http://vision.standford.edu/cs598_spring07/papers/Lecun98.pdf</a>
AlexNet ImageNet Classification with Deep Convolutional Neural Networks
VGGNet Very Deep Convolutional Networks for Large-Scale Visual Recognition
&lt;Network in Network&gt;
GoogLeNet &lt;Going Deeper With Covolutions&gt;
ResNet  Deep Residual Learning for Image Recognition
</p>


<p>
LeCun论文
Gradient-Based Learning Applied to Document Recognition
<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf</a>
</p>




<p>
池化的目的是什么？是如何达成的？
</p>

<p>
超参数影响的是模型训练过程，不会直接影响模型自身，更不是模型的参数。
</p>

<p>
可视化：
file_writer = tf.summary.FileWriter("/path/to/log", session.graph)
tensorboard.exe &#x2013;logdir=/path/to/log
打开localhost:6006
</p>

<p>
tf.nn.conv2d
tf.nn.relu
tf.nn.max_pool
tf.nn.dropout
tf.matmul
</p>

<p>
《FaceNet: A Unified Embedding for Face Recognition and Clustering》
</p>

<p>
LFW数据集<a href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a>
&lt;Generative Adversarial Networks&gt;
</p>

<p>
&lt;Revisiting Distrubited Synchronous SGD&gt;
</p>

<p>
使用Keras实现一个CNN
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #b22222;"># </span><span style="color: #b22222;">&#26694;&#26550;</span>
<span style="color: #a020f0;">from</span> tensorflow.keras <span style="color: #a020f0;">import</span> Sequential
<span style="color: #a020f0;">from</span> tensorflow.keras.layers <span style="color: #a020f0;">import</span> Flatten, Dense
<span style="color: #a020f0;">from</span> tensorflow.layers <span style="color: #a020f0;">import</span> Conv2D, MaxPooling2D

<span style="color: #a0522d;">model</span> = Sequential([
    Conv2D(32,
           kernel_size=(5, 5),
           strides=(1,1),
           activation=<span style="color: #8b2252;">'relu'</span>,
           input_shape=input_shape),
    MaxPooling2D(pool_size=(2,2),
                 strides=(2,2)),
    Conv2D(64,
           (5, 5),
           activation=<span style="color: #8b2252;">'relu'</span>),
    MaxPooling2D(pool_size=(2,2)),
    Flatten(),
    Dense(1000, activation=<span style="color: #8b2252;">'relu'</span>),
    Dense(num_classes, activation=<span style="color: #8b2252;">'softmax'</span>)
])


<span style="color: #a020f0;">print</span>(<span style="color: #8b2252;">'ok'</span>)
</pre>
</div>
<p>
RNN
</p>
<pre class="example">
tensorflow.keras.layers.SimpleRNN
</pre>
<p>
LTSM
</p>
<pre class="example">
tensorflow.keras.recurrent.LSTM
</pre>
<p>
手动编写LeCun
手动编写LeNet
试验可视化
</p>


<p>
tf.layers.Conv2D是一个二维卷积层。参数：
kernel_size，卷积窗口的高度和宽度。
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2019-09-23 周一 18:44</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
